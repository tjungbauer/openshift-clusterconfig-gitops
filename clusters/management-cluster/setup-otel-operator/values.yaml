---
otel: &channel-otel stable
otel-namespace: &otel-namespace openshift-opentelemetry-operator

######################################
# SUBCHART: helper-operator
# Operators that shall be installed.
######################################
helper-operator:
  operators:
    opentelemetry-product:
      enabled: true
      namespace:
        name: *otel-namespace
        create: true
      subscription:
        channel: *channel-otel
        approval: Automatic
        operatorName: opentelemetry-product
        source: redhat-operators
        sourceNamespace: openshift-marketplace
      operatorgroup:
        create: true
        notownnamespace: true

########################################
# SUBCHART: helper-status-checker
# Verify the status of a given operator.
########################################
helper-status-checker:
  enabled: true

  approver: false

  checks:
    - operatorName: opentelemetry-product
      namespace:
        name: *otel-namespace
      syncwave: 1

      serviceAccount:
        name: "status-checker-otel"

rh-build-of-opentelemetry:
  #########################################################################################
  # namespace ... disabled here, since we deployed it via Tempo already
  #########################################################################################
  namespace:
    name: tempostack
    create: false
  
  #########################################################################################
  # OPENTELEMETRY COLLECTOR - Production Configuration
  #########################################################################################
  collector:
    enabled: true
    name: otel
    mode: deployment
    replicas: 1
    
    serviceAccount: otel-collector-sa
    managementState: managed
    
    resources: {}
    
    nodeSelector:
      node-role.kubernetes.io/worker: ""
    
    tolerations: []
    
    config:
      receivers:
        # OTLP receivers for traces, metrics, and logs
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
        
        # Jaeger receiver (if migrating from Jaeger)
        jaeger:
          protocols:
            grpc:
              endpoint: 0.0.0.0:14250
            thrift_http:
              endpoint: 0.0.0.0:14268
      
      processors:
        # Batch processor for better throughput
        batch:
          timeout: 10s
          send_batch_size: 10000
          send_batch_max_size: 2048
        
        # Memory limiter to prevent OOM
        memory_limiter:
          check_interval: 1s
          limit_mib: 3500
          spike_limit_mib: 512
        
        # K8s attributes processor
        k8sattributes:
          auth_type: "serviceAccount"
          passthrough: false
          extract:
            metadata:
              - k8s.namespace.name
              - k8s.deployment.name
              - k8s.pod.name
              - k8s.pod.uid
              - k8s.node.name
      
      exporters:
        # Export traces to Tempo
        otlp/tempo:
          endpoint: tempo-gateway.tempo.svc.cluster.local:4317
          tls:
            insecure: false
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        
        # Export metrics to Prometheus
        prometheusremotewrite:
          endpoint: http://prometheus-server.monitoring.svc.cluster.local:9090/api/v1/write
          resource_to_telemetry_conversion:
            enabled: true
      
      service:
        pipelines:
          # Traces pipeline
          traces:
            receivers: [otlp, jaeger]
            processors: [memory_limiter, k8sattributes, resource, batch]
            exporters: [otlp/tempo]
          
          # Metrics pipeline
          metrics:
            receivers: [otlp, prometheus]
            processors: [memory_limiter, resource, batch]
            exporters: [prometheusremotewrite]
          
          # Logs pipeline
          logs:
            receivers: [otlp]
            processors: [memory_limiter, k8sattributes, resource, batch]
            exporters: [loki]
        
        telemetry:
          logs:
            level: info
          metrics:
            level: detailed
            address: 0.0.0.0:8888
  